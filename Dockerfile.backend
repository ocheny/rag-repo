FROM python:3.11-slim

ENV PYTHONDONTWRITEBYTECODE=1 \
    PYTHONUNBUFFERED=1 \
    HF_HUB_DISABLE_TELEMETRY=1 \
    PIP_NO_CACHE_DIR=1 \
    HF_HOME=/app/backend/store/hf_cache \
    TRANSFORMERS_CACHE=/app/backend/store/hf_cache \
    HUGGINGFACE_HUB_CACHE=/app/backend/store/hf_cache \
    HF_HUB_DISABLE_SYMLINKS_WARNING=1 \
    HF_HUB_ENABLE_HF_TRANSFER=1 \
    TOKENIZERS_PARALLELISM=false \
    OMP_NUM_THREADS=1

# libs mÃ­nimas para pillow/fitz
RUN apt-get update && apt-get install -y --no-install-recommends \
    libglib2.0-0 libgl1 tesseract-ocr \
    && rm -rf /var/lib/apt/lists/*

WORKDIR /app

# â”€â”€ Torch CPU 2.6 (evita CUDA y nvidia-*)
RUN python -m pip install --upgrade pip && \
    pip install --no-cache-dir --index-url https://download.pytorch.org/whl/cpu torch==2.6.0+cpu

# â”€â”€ Resto deps (sin torch)
COPY requirements.backend.txt .
RUN pip install --no-cache-dir -r requirements.backend.txt

# â”€â”€ CÃ³digo
COPY backend ./backend

# â”€â”€ Crea la carpeta de cache en build (evita race al inicio)
RUN mkdir -p /app/backend/store/hf_cache

# ðŸš€ Fuerza la descarga del modelo en build time
RUN python -c "from sentence_transformers import SentenceTransformer; SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2', cache_folder='/app/backend/store/hf_cache')"

# Railway suele inyectar $PORT=8080; si no existe, usa 8000
EXPOSE 8080
CMD uvicorn backend.main:app --host 0.0.0.0 --port ${PORT:-8080} --workers 1
